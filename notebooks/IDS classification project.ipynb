{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdc236f3-1f44-4c65-bac3-7fe7e067120f",
   "metadata": {},
   "source": [
    "# IDS classification using NSL-KDD dataset\n",
    "\n",
    "Released by Th√©ophane Dumas and Cyrille Tryer\n",
    "\n",
    "### Goal\n",
    "\n",
    "The goal of this project was to compare two classification models that can be used by an Intrusion Detection System.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "We use the well known NSL-KDD model.\n",
    "\n",
    "### References\n",
    "\n",
    "This report is inspired from this work : [https://github.com/thinline72/nsl-kdd](https://github.com/thinline72/nsl-kdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e59356-106d-4cca-964b-8221a3c1a4a4",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "\n",
    "First we connect to Spark, and we load the dataset.\n",
    "\n",
    "This dataset contains 41 features like protocol_type or service. These feature describe a network connexion, a label is associated to the connexion like normal, apache2 or satan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfc54638-b297-4738-a42b-abb6fe2c75e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_extract, udf\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf, split, col\n",
    "import pyspark.sql.functions as sql\n",
    "\n",
    "context = SparkSession.builder.appName('projet').getOrCreate().sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "736ce200-fa9d-44ab-93fc-6c695b69b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load dataset and divide it into 8 partitions\n",
    "col_names = np.array([\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"labels\"])\n",
    "\n",
    "def load_dataset(path):\n",
    "    dataset_rdd = context.textFile(path, 8).map(lambda line: line.split(','))\n",
    "    dataset_df = (dataset_rdd.toDF(col_names.tolist()).select(\n",
    "                    col('duration').cast(DoubleType()),\n",
    "                    col('protocol_type').cast(StringType()),\n",
    "                    col('service').cast(StringType()),\n",
    "                    col('flag').cast(StringType()),\n",
    "                    col('src_bytes').cast(DoubleType()),\n",
    "                    col('dst_bytes').cast(DoubleType()),\n",
    "                    col('land').cast(DoubleType()),\n",
    "                    col('wrong_fragment').cast(DoubleType()),\n",
    "                    col('urgent').cast(DoubleType()),\n",
    "                    col('hot').cast(DoubleType()),\n",
    "                    col('num_failed_logins').cast(DoubleType()),\n",
    "                    col('logged_in').cast(DoubleType()),\n",
    "                    col('num_compromised').cast(DoubleType()),\n",
    "                    col('root_shell').cast(DoubleType()),\n",
    "                    col('su_attempted').cast(DoubleType()),\n",
    "                    col('num_root').cast(DoubleType()),\n",
    "                    col('num_file_creations').cast(DoubleType()),\n",
    "                    col('num_shells').cast(DoubleType()),\n",
    "                    col('num_access_files').cast(DoubleType()),\n",
    "                    col('num_outbound_cmds').cast(DoubleType()),\n",
    "                    col('is_host_login').cast(DoubleType()),\n",
    "                    col('is_guest_login').cast(DoubleType()),\n",
    "                    col('count').cast(DoubleType()),\n",
    "                    col('srv_count').cast(DoubleType()),\n",
    "                    col('serror_rate').cast(DoubleType()),\n",
    "                    col('srv_serror_rate').cast(DoubleType()),\n",
    "                    col('rerror_rate').cast(DoubleType()),\n",
    "                    col('srv_rerror_rate').cast(DoubleType()),\n",
    "                    col('same_srv_rate').cast(DoubleType()),\n",
    "                    col('diff_srv_rate').cast(DoubleType()),\n",
    "                    col('srv_diff_host_rate').cast(DoubleType()),\n",
    "                    col('dst_host_count').cast(DoubleType()),\n",
    "                    col('dst_host_srv_count').cast(DoubleType()),\n",
    "                    col('dst_host_same_srv_rate').cast(DoubleType()),\n",
    "                    col('dst_host_diff_srv_rate').cast(DoubleType()),\n",
    "                    col('dst_host_same_src_port_rate').cast(DoubleType()),\n",
    "                    col('dst_host_srv_diff_host_rate').cast(DoubleType()),\n",
    "                    col('dst_host_serror_rate').cast(DoubleType()),\n",
    "                    col('dst_host_srv_serror_rate').cast(DoubleType()),\n",
    "                    col('dst_host_rerror_rate').cast(DoubleType()),\n",
    "                    col('dst_host_srv_rerror_rate').cast(DoubleType()),\n",
    "                    col('labels').cast(StringType())))\n",
    "\n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a5a3efa-1e4d-48a7-bd64-c6f936bfd82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_dataset('kdd/KDDTrain+.txt')\n",
    "test = load_dataset('kdd/KDDTest+.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b97016ea-1201-436d-81df-1d5a8577de06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of lines loaded : 148517\n"
     ]
    }
   ],
   "source": [
    "print('number of lines loaded :', train.count() + test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f884aad-801d-4b16-9f82-7bad64105d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Top 10 labels :\n",
      "+-----------+-----+\n",
      "|     labels|count|\n",
      "+-----------+-----+\n",
      "|     normal|67343|\n",
      "|    neptune|41214|\n",
      "|      satan| 3633|\n",
      "|    ipsweep| 3599|\n",
      "|  portsweep| 2931|\n",
      "|      smurf| 2646|\n",
      "|       nmap| 1493|\n",
      "|       back|  956|\n",
      "|   teardrop|  892|\n",
      "|warezclient|  890|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('# Top 10 labels :')\n",
    "train.groupBy('labels').count().sort('count', ascending=False).limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb0040e5-32ec-4197-91c0-f76971c7a1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Top 10 services :\n",
      "+--------+-----+\n",
      "| service|count|\n",
      "+--------+-----+\n",
      "|    http|40338|\n",
      "| private|21853|\n",
      "|domain_u| 9043|\n",
      "|    smtp| 7313|\n",
      "|ftp_data| 6860|\n",
      "|   eco_i| 4586|\n",
      "|   other| 4359|\n",
      "|   ecr_i| 3077|\n",
      "|  telnet| 2353|\n",
      "|  finger| 1767|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('# Top 10 services :')\n",
    "train.groupBy('service').count().sort('count', ascending=False).limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3925a0d-6457-4663-85df-93051441dcf0",
   "metadata": {},
   "source": [
    "# Pipeline definition\n",
    "\n",
    "We define a pipeline to format train & test datasets for classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35ef9c7b-e310-4c93-8a6b-b2c9a0197315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark import keyword_only\n",
    "\n",
    "# We simplify class like in https://github.com/thinline72/nsl-kdd.\n",
    "\n",
    "attack_dict = {\n",
    "    'normal': 'normal',\n",
    "    \n",
    "    'back': 'DoS',\n",
    "    'land': 'DoS',\n",
    "    'neptune': 'DoS',\n",
    "    'pod': 'DoS',\n",
    "    'smurf': 'DoS',\n",
    "    'teardrop': 'DoS',\n",
    "    'mailbomb': 'DoS',\n",
    "    'apache2': 'DoS',\n",
    "    'processtable': 'DoS',\n",
    "    'udpstorm': 'DoS',\n",
    "    \n",
    "    'ipsweep': 'scan',\n",
    "    'nmap': 'scan',\n",
    "    'portsweep': 'scan',\n",
    "    'satan': 'scan',\n",
    "    'mscan': 'scan',\n",
    "    'saint': 'scan',\n",
    "\n",
    "    'ftp_write': 'R2L',\n",
    "    'guess_passwd': 'R2L',\n",
    "    'imap': 'R2L',\n",
    "    'multihop': 'R2L',\n",
    "    'phf': 'R2L',\n",
    "    'spy': 'R2L',\n",
    "    'warezclient': 'R2L',\n",
    "    'warezmaster': 'R2L',\n",
    "    'sendmail': 'R2L',\n",
    "    'named': 'R2L',\n",
    "    'snmpgetattack': 'R2L',\n",
    "    'snmpguess': 'R2L',\n",
    "    'xlock': 'R2L',\n",
    "    'xsnoop': 'R2L',\n",
    "    'worm': 'R2L',\n",
    "    \n",
    "    'buffer_overflow': 'privesc',\n",
    "    'loadmodule': 'privesc',\n",
    "    'perl': 'privesc',\n",
    "    'rootkit': 'privesc',\n",
    "    'httptunnel': 'privesc',\n",
    "    'ps': 'privesc',    \n",
    "    'sqlattack': 'privesc',\n",
    "    'xterm': 'privesc'\n",
    "}\n",
    "\n",
    "attack_mapping_udf = udf(lambda v: attack_dict[v])\n",
    "\n",
    "train = train.withColumn('labels5', attack_mapping_udf(train['labels']))\n",
    "test = test.withColumn('labels5', attack_mapping_udf(test['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "547973af-f24c-40b6-a335-f3e9c0c716d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['protocol_type_idx', 'service_idx', 'flag_idx', 'labels_idx', 'duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, UnivariateFeatureSelector, VarianceThresholdSelector\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "stages = []\n",
    "\n",
    "feature_names = []\n",
    "\n",
    "for col in test.schema :\n",
    "    if str(col.dataType) == 'StringType':\n",
    "        try:\n",
    "            si = StringIndexer(inputCol = col.name, outputCol = col.name + '_idx')\n",
    "            stages += [si]\n",
    "            feature_names += [col.name + '_idx']\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "feature_names += [col.name for col in train.schema if col.name not in [\"labels\", \"protocol_type\", \"service\", \"flag\"] and str(col.dataType) == 'DoubleType' ]\n",
    "feature_names.remove('labels5_idx')\n",
    "print(feature_names)\n",
    "\n",
    "assembler = VectorAssembler(outputCol=\"features\", inputCols=feature_names)\n",
    "\n",
    "stages += [assembler]\n",
    "\n",
    "normalizer = StandardScaler(inputCol=\"features\", outputCol=\"normFeatures\")\n",
    "stages += [normalizer]\n",
    "\n",
    "selector = UnivariateFeatureSelector(featuresCol=\"normFeatures\", outputCol=\"selectedFeatures\",\n",
    "                                     labelCol=\"labels5_idx\", selectionMode=\"numTopFeatures\")\n",
    "selector.setFeatureType(\"continuous\").setLabelType(\"categorical\").setSelectionThreshold(10)\n",
    "# selector = VarianceThresholdSelector(varianceThreshold=0.1, outputCol=\"selectedFeatures\", featuresCol=\"normFeatures\")\n",
    "# old one was 0.2\n",
    "stages += [selector]\n",
    "\n",
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1724721-4364-4a09-8db9-c16ba82005a7",
   "metadata": {},
   "source": [
    "Then we use pipeline to transform datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6204bac7-ca76-463f-b75c-7d7f8d9afee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "train_data = pipeline.fit(train).transform(train)\n",
    "train_data = train_data.withColumnRenamed(\"labels_idx\", \"label\")\n",
    "train_data = train_data.drop(\"features\")\n",
    "train_data = train_data.withColumnRenamed(\"selectedFeatures\", \"features\")\n",
    "\n",
    "test_data = pipeline.fit(test).transform(test)\n",
    "test_data = test_data.withColumnRenamed(\"labels_idx\", \"label\")\n",
    "test_data = test_data.drop(\"features\")\n",
    "test_data = test_data.withColumnRenamed(\"selectedFeatures\", \"features\")\n",
    "\n",
    "# train_data.select('normFeatures').limit(1).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d43adf5-0a69-4e0d-889e-2f9992fd74ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0.0, 0.3364698152787053, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features\n",
       "0  (0.0, 0.3364698152787053, 0.0, 0.0, 0.0, 0.0, ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.select('features').limit(1).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dabb89-9e90-469b-843b-f2e1d764abcd",
   "metadata": {},
   "source": [
    "# Prediction with NaiveBayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8ae6c37-80ee-4052-ba5a-9dd175848938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naives Bayes\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "naive_bayes_model = nb.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3f18ee6-155b-4962-8980-2e28e97fbbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 predictions : \n",
      "+-----+----------+--------------------+\n",
      "|label|prediction|         probability|\n",
      "+-----+----------+--------------------+\n",
      "|  1.0|       1.0|[0.02015479803007...|\n",
      "|  1.0|       1.0|[0.02015479803007...|\n",
      "|  0.0|       1.0|[0.31790218781455...|\n",
      "| 11.0|       5.0|[2.56200448974404...|\n",
      "|  3.0|       1.0|[5.59283618338924...|\n",
      "|  0.0|       0.0|[0.96335851943539...|\n",
      "|  0.0|       0.0|[0.99901550276848...|\n",
      "|  2.0|      11.0|[4.37636473286757...|\n",
      "|  0.0|       0.0|[0.99569162698957...|\n",
      "|  2.0|      11.0|[1.39622670385850...|\n",
      "+-----+----------+--------------------+\n",
      "\n",
      "accuracy in test dataset : 0.9306079252302235\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "predictions = naive_bayes_model.transform(test_data)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\")\n",
    "naive_bayes_accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print('First 10 predictions : ')\n",
    "predictions.limit(10).select(\"label\", \"prediction\", \"probability\").show()\n",
    "\n",
    "print('accuracy in test dataset :', naive_bayes_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a54e802-2d04-4a84-9cdd-727242e004ea",
   "metadata": {},
   "source": [
    "# Prediction with LogisticRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37f5f29e-b061-4fb1-b93b-0d7c785d9442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multinomial logistic regression\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "\n",
    "logic_reg = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "276cbdc0-4c36-4111-95dc-58e74f2544f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 predictions : \n",
      "+-----+----------+--------------------+\n",
      "|label|prediction|         probability|\n",
      "+-----+----------+--------------------+\n",
      "|  1.0|       0.0|[0.47990642848867...|\n",
      "|  1.0|       0.0|[0.47990642848867...|\n",
      "|  0.0|       0.0|[0.48620687209608...|\n",
      "| 11.0|       0.0|[0.41757690374265...|\n",
      "|  3.0|       0.0|[0.46732668598615...|\n",
      "|  0.0|       0.0|[0.64218678280572...|\n",
      "|  0.0|       0.0|[0.64218678280572...|\n",
      "|  2.0|       0.0|[0.47361236973570...|\n",
      "|  0.0|       0.0|[0.64218678280572...|\n",
      "|  2.0|       0.0|[0.47361236973570...|\n",
      "+-----+----------+--------------------+\n",
      "\n",
      "accuracy in test dataset : 0.5311696407698902\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "predictions = logic_reg.transform(test_data)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\")\n",
    "logistic_reg_accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print('First 10 predictions : ')\n",
    "predictions.limit(10).select(\"label\", \"prediction\", \"probability\").show()\n",
    "\n",
    "print('accuracy in test dataset :', logistic_reg_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128624c0-6a47-42e1-93cc-58826065ff5e",
   "metadata": {},
   "source": [
    "# Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a55d0b1-0a46-4551-8309-fdf88c938d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(numTrees=4)\n",
    "random_forest_model = rfc.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d98d8988-1720-43b4-8591-49323e6e0854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 predictions : \n",
      "+-----+----------+--------------------+\n",
      "|label|prediction|         probability|\n",
      "+-----+----------+--------------------+\n",
      "|  1.0|       0.0|[1.0,0.0,0.0,0.0,...|\n",
      "|  1.0|       0.0|[1.0,0.0,0.0,0.0,...|\n",
      "|  0.0|       0.0|[1.0,0.0,0.0,0.0,...|\n",
      "| 11.0|       5.0|[0.0,0.0,0.128571...|\n",
      "|  3.0|       2.0|[0.0,0.4448665880...|\n",
      "|  0.0|       0.0|[0.99688548423171...|\n",
      "|  0.0|       0.0|[1.0,0.0,0.0,0.0,...|\n",
      "|  2.0|       2.0|[0.24923234390992...|\n",
      "|  0.0|       0.0|[0.99688548423171...|\n",
      "|  2.0|       2.0|[0.0,0.2499999999...|\n",
      "|  3.0|       2.0|[0.24923234390992...|\n",
      "|  0.0|       0.0|[1.0,0.0,0.0,0.0,...|\n",
      "|  1.0|       0.0|[1.0,0.0,0.0,0.0,...|\n",
      "|  1.0|       0.0|[1.0,0.0,0.0,0.0,...|\n",
      "|  0.0|       0.0|[0.98500967117988...|\n",
      "|  0.0|       0.0|[0.99688548423171...|\n",
      "|  0.0|       0.0|[0.99688548423171...|\n",
      "|  0.0|       0.0|[0.99688548423171...|\n",
      "|  0.0|       0.0|[0.82526636225266...|\n",
      "|  1.0|       0.0|[1.0,0.0,0.0,0.0,...|\n",
      "+-----+----------+--------------------+\n",
      "\n",
      "accuracy in test dataset : 0.8177355255980675\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "predictions = random_forest_model.transform(test_data)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\")\n",
    "random_forest_accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print('First 10 predictions : ')\n",
    "predictions.limit(20).select(\"label\", \"prediction\", \"probability\").show()\n",
    "\n",
    "print('accuracy in test dataset :', random_forest_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789650b7-2d24-49e6-bad3-ae23695000af",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d5d6085-138e-4fb8-9cc2-7190a5d69714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The most effective model is Naive Bayes. with an accuracy of 0.9306079252302235\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "x =  ['Naive Bayes', 'Logistic Reggression', 'Random forest']\n",
    "y = [naive_bayes_accuracy, logistic_reg_accuracy, random_forest_accuracy]\n",
    "\n",
    "plt.bar(x, y)\n",
    "\n",
    "acc_max = x[y.index(max(y))]\n",
    "print('\\nThe most effective model is %s. with an accuracy of %s' % (acc_max, max(y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
